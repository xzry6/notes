{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Playground\n",
    "\n",
    "This is a tutorial for better understanding the concept and syntax of **Tensorflow**. In this tutorial, we assume you already have the basic knowledge of **Python** and **Machine Learning**. You can fill the blank lines, run the script and see what would happen according to the code. This tutorial will begin with some style advice and some basic concepts, following by some exercises of different **Machine Learnig** models.\n",
    "\n",
    "###### Please feel free to add some chapters if you think it might be good for our group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "* Tensorflow Basics\n",
    "    * [Style Guide](chapters/1-style.ipynb)\n",
    "    * [Tensorflow Basics](chapters/2-basics.ipynb)\n",
    "    * [Graph](chapters/3-graph.ipynb)\n",
    "    * [Summary and Tensorboard](chapters/4-summary.ipynb)\n",
    "* Deep Learning in TF\n",
    "    * [Neural Network](chapters/5-ann.ipynb)\n",
    "    * [Autoencoder](chapters/6-autoencoder.ipynb)\n",
    "    * [Convolutional Neural Network](chapters/7-cnn.ipynb)\n",
    "    * [Recurrent Neural Network](chapters/8-rnn.ipynb)\n",
    "* Clustering\n",
    "    * [Distributed Mode](chapters/9-distributed.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Code\n",
    "\n",
    "Here is a sample **Tensorflow** code, play around and grab as much information as you can here. We'll explain it in detail in later chapters. When you think the code is ready, toggle the **\"run cell\"** button in the menu bar and see what will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 0, weight: 0.098388, bias: 0.440273\n",
      "steps: 20, weight: 0.081874, bias: 0.310411\n",
      "steps: 40, weight: 0.094683, bias: 0.303054\n",
      "steps: 60, weight: 0.098440, bias: 0.300896\n",
      "steps: 80, weight: 0.099542, bias: 0.300263\n",
      "steps: 100, weight: 0.099866, bias: 0.300077\n",
      "steps: 120, weight: 0.099961, bias: 0.300023\n",
      "steps: 140, weight: 0.099988, bias: 0.300007\n",
      "steps: 160, weight: 0.099997, bias: 0.300002\n",
      "steps: 180, weight: 0.099999, bias: 0.300001\n",
      "steps: 200, weight: 0.100000, bias: 0.300000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "## input\n",
    "\n",
    "# randomly generate 100 instances with float type\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "# create a linear model: y = x * 0.1 + 0.3\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "\n",
    "## build the graph(we already know w = 0.3 and b = 0.1 though, tensorflow will figure it out by its own)\n",
    "\n",
    "# initialize uniform distributed weight vector\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "# initialize bias to 0\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "# define the graph\n",
    "y = W * x_data + b\n",
    "\n",
    "# define the loss function\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "# using gradient descent minimize the loss \n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "## initialization and launch the graph\n",
    "\n",
    "# define the initialization\n",
    "init = tf.initialize_all_variables()\n",
    "# get a session and initialize the variables\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "## training\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(\"steps: %i, weight: %f, bias: %f\" % (step, sess.run(W), sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above sample, we defined a set of random inputs with `y = 0.1 * x + 0.3` and let our linear model `y = W * x + b` to learn the inputs in 200 training epochs. Results are printed per 20 time steps. `W` and `b` should be quite close to 0.1 and 0.3 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next Chapter: Style Guide](chapters/1-style.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
